{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ft4xndxawDX_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string \n",
    "import re \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qU3Mk1p2wDYI",
    "outputId": "b3d9a528-c2d5-44c0-ab63-0fa5f8223300"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340539111971516416</td>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>Aggregator of Asian American news; scanning di...</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>['PfizerBioNTech']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1338158543359250433</td>\n",
       "      <td>Albert Fong</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Marketing dude, tech geek, heavy metal &amp; '80s ...</td>\n",
       "      <td>2009-09-21 15:27:30</td>\n",
       "      <td>834</td>\n",
       "      <td>666</td>\n",
       "      <td>178</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-13 16:27:13</td>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337858199140118533</td>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>heil, hydra üñê‚ò∫</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "      <td>['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1337855739918835717</td>\n",
       "      <td>Charles Adler</td>\n",
       "      <td>Vancouver, BC - Canada</td>\n",
       "      <td>Hosting \"CharlesAdlerTonight\" Global News Radi...</td>\n",
       "      <td>2008-09-10 11:28:53</td>\n",
       "      <td>49165</td>\n",
       "      <td>3933</td>\n",
       "      <td>21853</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-12-12 20:23:59</td>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>446</td>\n",
       "      <td>2129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1337854064604966912</td>\n",
       "      <td>Citizen News Channel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen News Channel bringing you an alternati...</td>\n",
       "      <td>2020-04-23 17:58:42</td>\n",
       "      <td>152</td>\n",
       "      <td>580</td>\n",
       "      <td>1473</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:17:19</td>\n",
       "      <td>Explain to me again why we need a vaccine @Bor...</td>\n",
       "      <td>['whereareallthesickpeople', 'PfizerBioNTech']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id             user_name              user_location  \\\n",
       "0  1340539111971516416            Rachel Roh  La Crescenta-Montrose, CA   \n",
       "1  1338158543359250433           Albert Fong          San Francisco, CA   \n",
       "2  1337858199140118533              eliüá±üáπüá™üá∫üëå                   Your Bed   \n",
       "3  1337855739918835717         Charles Adler     Vancouver, BC - Canada   \n",
       "4  1337854064604966912  Citizen News Channel                        NaN   \n",
       "\n",
       "                                    user_description         user_created  \\\n",
       "0  Aggregator of Asian American news; scanning di...  2009-04-08 17:52:46   \n",
       "1  Marketing dude, tech geek, heavy metal & '80s ...  2009-09-21 15:27:30   \n",
       "2                                     heil, hydra üñê‚ò∫  2020-06-25 23:30:28   \n",
       "3  Hosting \"CharlesAdlerTonight\" Global News Radi...  2008-09-10 11:28:53   \n",
       "4  Citizen News Channel bringing you an alternati...  2020-04-23 17:58:42   \n",
       "\n",
       "   user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0             405          1692             3247          False   \n",
       "1             834           666              178          False   \n",
       "2              10            88              155          False   \n",
       "3           49165          3933            21853           True   \n",
       "4             152           580             1473          False   \n",
       "\n",
       "                  date                                               text  \\\n",
       "0  2020-12-20 06:06:44  Same folks said daikon paste could treat a cyt...   \n",
       "1  2020-12-13 16:27:13  While the world has been on the wrong side of ...   \n",
       "2  2020-12-12 20:33:45  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n",
       "3  2020-12-12 20:23:59  Facts are immutable, Senator, even when you're...   \n",
       "4  2020-12-12 20:17:19  Explain to me again why we need a vaccine @Bor...   \n",
       "\n",
       "                                            hashtags               source  \\\n",
       "0                                 ['PfizerBioNTech']  Twitter for Android   \n",
       "1                                                NaN      Twitter Web App   \n",
       "2  ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...  Twitter for Android   \n",
       "3                                                NaN      Twitter Web App   \n",
       "4     ['whereareallthesickpeople', 'PfizerBioNTech']   Twitter for iPhone   \n",
       "\n",
       "   retweets  favorites  is_retweet  \n",
       "0         0          0       False  \n",
       "1         1          1       False  \n",
       "2         0          0       False  \n",
       "3       446       2129       False  \n",
       "4         0          0       False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('vaccination_tweets.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qg1D-6hpwDYJ"
   },
   "source": [
    "# Dataset Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i9b2JnlZwDYJ",
    "outputId": "04c3ab1b-4848-47af-ed63-e323261490ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4560, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3ba0B8E_wDYJ",
    "outputId": "fda47e2a-08f4-48b3-a2ce-9971a1902786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4560 entries, 0 to 4559\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                4560 non-null   int64 \n",
      " 1   user_name         4560 non-null   object\n",
      " 2   user_location     3626 non-null   object\n",
      " 3   user_description  4279 non-null   object\n",
      " 4   user_created      4560 non-null   object\n",
      " 5   user_followers    4560 non-null   int64 \n",
      " 6   user_friends      4560 non-null   int64 \n",
      " 7   user_favourites   4560 non-null   int64 \n",
      " 8   user_verified     4560 non-null   bool  \n",
      " 9   date              4560 non-null   object\n",
      " 10  text              4560 non-null   object\n",
      " 11  hashtags          3381 non-null   object\n",
      " 12  source            4559 non-null   object\n",
      " 13  retweets          4560 non-null   int64 \n",
      " 14  favorites         4560 non-null   int64 \n",
      " 15  is_retweet        4560 non-null   bool  \n",
      "dtypes: bool(2), int64(6), object(8)\n",
      "memory usage: 507.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tSpaIu3lwDYK",
    "outputId": "7e0d042a-832c-404d-ebb1-59e2132c523f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.560000e+03</td>\n",
       "      <td>4.560000e+03</td>\n",
       "      <td>4560.000000</td>\n",
       "      <td>4560.000000</td>\n",
       "      <td>4560.000000</td>\n",
       "      <td>4560.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.345594e+18</td>\n",
       "      <td>4.138516e+04</td>\n",
       "      <td>1183.621053</td>\n",
       "      <td>13464.289693</td>\n",
       "      <td>1.768640</td>\n",
       "      <td>10.476316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.721674e+15</td>\n",
       "      <td>3.612069e+05</td>\n",
       "      <td>2709.733574</td>\n",
       "      <td>39068.344185</td>\n",
       "      <td>15.678197</td>\n",
       "      <td>73.424858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.337728e+18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.341212e+18</td>\n",
       "      <td>1.127500e+02</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>385.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.346231e+18</td>\n",
       "      <td>4.880000e+02</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>1977.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.349704e+18</td>\n",
       "      <td>2.211750e+03</td>\n",
       "      <td>1247.250000</td>\n",
       "      <td>10044.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.353992e+18</td>\n",
       "      <td>1.371493e+07</td>\n",
       "      <td>99143.000000</td>\n",
       "      <td>924667.000000</td>\n",
       "      <td>678.000000</td>\n",
       "      <td>2307.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  user_followers  user_friends  user_favourites  \\\n",
       "count  4.560000e+03    4.560000e+03   4560.000000      4560.000000   \n",
       "mean   1.345594e+18    4.138516e+04   1183.621053     13464.289693   \n",
       "std    4.721674e+15    3.612069e+05   2709.733574     39068.344185   \n",
       "min    1.337728e+18    0.000000e+00      0.000000         0.000000   \n",
       "25%    1.341212e+18    1.127500e+02    167.000000       385.750000   \n",
       "50%    1.346231e+18    4.880000e+02    465.000000      1977.500000   \n",
       "75%    1.349704e+18    2.211750e+03   1247.250000     10044.750000   \n",
       "max    1.353992e+18    1.371493e+07  99143.000000    924667.000000   \n",
       "\n",
       "          retweets    favorites  \n",
       "count  4560.000000  4560.000000  \n",
       "mean      1.768640    10.476316  \n",
       "std      15.678197    73.424858  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     1.000000  \n",
       "75%       1.000000     5.000000  \n",
       "max     678.000000  2307.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9R2StPRwDYK"
   },
   "source": [
    "# Data Cleansing Part\n",
    "    1.Removing html tag\n",
    "    2.Removing Punctuation\n",
    "    3.Special Character\n",
    "    4.Conver text into lower case\n",
    "    5.Remove emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "scq75xPMwDYL"
   },
   "outputs": [],
   "source": [
    "def DataCleansing(text):\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text= re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = str(text).lower()\n",
    "    return text\n",
    "    \n",
    "\n",
    "data['text'] = data['text'].apply(lambda x:DataCleansing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9Cv39-n4wDYL",
    "outputId": "fe617c78-4b7d-4e4d-a2de-046e5271195c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     same folks said daikon paste could treat a cyt...\n",
       "1     while the world has been on the wrong side of ...\n",
       "2     coronavirus sputnikv astrazeneca pfizerbiontec...\n",
       "3     facts are immutable senator even when youre no...\n",
       "4     explain to me again why we need a vaccine bori...\n",
       "5     does anyone have any useful adviceguidance for...\n",
       "6     it is a bit sad to claim the fame for success ...\n",
       "7     there have not been many bright days in  but h...\n",
       "8     covid vaccine you getting it covidvaccine  pfi...\n",
       "9     covidvaccine states will start getting  monday...\n",
       "10    while deaths are closing in on the  mark milli...\n",
       "11    cnnbrk  covidvaccine vaccine corona pfizerbion...\n",
       "12    the agency also released new information for h...\n",
       "13    for all the women and healthcare providers who...\n",
       "14    expect  sites across all the states to receive...\n",
       "15    trump announces vaccine rollout in less than  ...\n",
       "16    updated yellowfever amp  immunitypassports  pa...\n",
       "17    coronavirus iran reports  new cases  deaths in...\n",
       "18    pfizer will rake in billions from its expensiv...\n",
       "19    the trump administration failed to deliver on ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][:20] #Reading data in a itarative way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kLKmcj3YwDYL",
    "outputId": "489d676c-7720-42dd-a1ae-fc59d0723b48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4540    it‚Äôs been  days since i got the pfizerbiontech...\n",
       "4541    philippine president rodrigoduterte said he wo...\n",
       "4542    norwayüá≥üá¥ considers excluding terminally ill pe...\n",
       "4543    jkenney sure everyone knows trudeau heads up t...\n",
       "4544    tomei hoje a segunda dose da vacina contra a  ...\n",
       "4545    morning it‚Äôs now about  hours post second dose...\n",
       "4546    dubai üá¶üá™ plans to inoculate  of its population...\n",
       "4547    the coronavirus is a serious threat only to pe...\n",
       "4548     vaccinationcentre bushey watford elstree hert...\n",
       "4549    vaccinator today  giving hope to everyone  vac...\n",
       "4550    a peek behind the vaccine makers curtainüëÄ pfiz...\n",
       "4551    dr gregory michael died of immune thrombocytic...\n",
       "4552     second pfizer vaccine dose completed this mor...\n",
       "4553    spain has now started to administer second jab...\n",
       "4554    union health ministry reported  cases of adver...\n",
       "4555    status  hrs after  pfizerbiontech vaccine shoo...\n",
       "4556    thankyou üëè to  roscommon vaccination team for ...\n",
       "4557     covid vaccine jab administered quick easy and...\n",
       "4558     vaccine jab done today very efficiently done ...\n",
       "4559    is the  vaccineüíâ safe yes deaths reported in n...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbYWbXrPwDYM"
   },
   "source": [
    "# Removing emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V2TBcXqMwDYM",
    "outputId": "f621a701-9f0e-4716-96d2-1742f2e7c20f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4540    it‚Äôs been  days since i got the pfizerbiontech...\n",
       "4541    philippine president rodrigoduterte said he wo...\n",
       "4542    norway considers excluding terminally ill peop...\n",
       "4543    jkenney sure everyone knows trudeau heads up t...\n",
       "4544    tomei hoje a segunda dose da vacina contra a  ...\n",
       "4545    morning it‚Äôs now about  hours post second dose...\n",
       "4546    dubai  plans to inoculate  of its population w...\n",
       "4547    the coronavirus is a serious threat only to pe...\n",
       "4548     vaccinationcentre bushey watford elstree hert...\n",
       "4549    vaccinator today  giving hope to everyone  vac...\n",
       "4550    a peek behind the vaccine makers curtain pfize...\n",
       "4551    dr gregory michael died of immune thrombocytic...\n",
       "4552     second pfizer vaccine dose completed this mor...\n",
       "4553    spain has now started to administer second jab...\n",
       "4554    union health ministry reported  cases of adver...\n",
       "4555    status  hrs after  pfizerbiontech vaccine shoo...\n",
       "4556    thankyou  to  roscommon vaccination team for a...\n",
       "4557     covid vaccine jab administered quick easy and...\n",
       "4558     vaccine jab done today very efficiently done ...\n",
       "4559    is the  vaccine safe yes deaths reported in no...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x:remove_emoji(x))\n",
    "data['text'].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfjuspyrwDYN"
   },
   "source": [
    "# Creating New DataFrame For Further Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "G-4X-3wvwDYN",
    "outputId": "db22860e-f982-4873-d840-a737088bef2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4540</th>\n",
       "      <td>it‚Äôs been  days since i got the pfizerbiontech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>philippine president rodrigoduterte said he wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542</th>\n",
       "      <td>norway considers excluding terminally ill peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>jkenney sure everyone knows trudeau heads up t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>tomei hoje a segunda dose da vacina contra a  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>morning it‚Äôs now about  hours post second dose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>dubai  plans to inoculate  of its population w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>the coronavirus is a serious threat only to pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>vaccinationcentre bushey watford elstree hert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>vaccinator today  giving hope to everyone  vac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>a peek behind the vaccine makers curtain pfize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>dr gregory michael died of immune thrombocytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>second pfizer vaccine dose completed this mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>spain has now started to administer second jab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4554</th>\n",
       "      <td>union health ministry reported  cases of adver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>status  hrs after  pfizerbiontech vaccine shoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4556</th>\n",
       "      <td>thankyou  to  roscommon vaccination team for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4557</th>\n",
       "      <td>covid vaccine jab administered quick easy and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4558</th>\n",
       "      <td>vaccine jab done today very efficiently done ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>is the  vaccine safe yes deaths reported in no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "4540  it‚Äôs been  days since i got the pfizerbiontech...\n",
       "4541  philippine president rodrigoduterte said he wo...\n",
       "4542  norway considers excluding terminally ill peop...\n",
       "4543  jkenney sure everyone knows trudeau heads up t...\n",
       "4544  tomei hoje a segunda dose da vacina contra a  ...\n",
       "4545  morning it‚Äôs now about  hours post second dose...\n",
       "4546  dubai  plans to inoculate  of its population w...\n",
       "4547  the coronavirus is a serious threat only to pe...\n",
       "4548   vaccinationcentre bushey watford elstree hert...\n",
       "4549  vaccinator today  giving hope to everyone  vac...\n",
       "4550  a peek behind the vaccine makers curtain pfize...\n",
       "4551  dr gregory michael died of immune thrombocytic...\n",
       "4552   second pfizer vaccine dose completed this mor...\n",
       "4553  spain has now started to administer second jab...\n",
       "4554  union health ministry reported  cases of adver...\n",
       "4555  status  hrs after  pfizerbiontech vaccine shoo...\n",
       "4556  thankyou  to  roscommon vaccination team for a...\n",
       "4557   covid vaccine jab administered quick easy and...\n",
       "4558   vaccine jab done today very efficiently done ...\n",
       "4559  is the  vaccine safe yes deaths reported in no..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df=pd.DataFrame()\n",
    "new_df['text']=data['text']\n",
    "new_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2kp08nYwDYQ"
   },
   "source": [
    "# Vader Analysis For Labelling Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BCby2N5BwDYR",
    "outputId": "aa463b56-3cba-4fba-9210-38141eeb5e14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936\n",
      "-0.9294\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>while the world has been on the wrong side of ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus sputnikv astrazeneca pfizerbiontec...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facts are immutable senator even when youre no...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explain to me again why we need a vaccine bori...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>status  hrs after  pfizerbiontech vaccine shoo...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4556</th>\n",
       "      <td>thankyou  to  roscommon vaccination team for a...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4557</th>\n",
       "      <td>covid vaccine jab administered quick easy and...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4558</th>\n",
       "      <td>vaccine jab done today very efficiently done ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>is the  vaccine safe yes deaths reported in no...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4560 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     same folks said daikon paste could treat a cyt...  Positive\n",
       "1     while the world has been on the wrong side of ...  Negative\n",
       "2     coronavirus sputnikv astrazeneca pfizerbiontec...  Positive\n",
       "3     facts are immutable senator even when youre no...   Neutral\n",
       "4     explain to me again why we need a vaccine bori...   Neutral\n",
       "...                                                 ...       ...\n",
       "4555  status  hrs after  pfizerbiontech vaccine shoo...  Negative\n",
       "4556  thankyou  to  roscommon vaccination team for a...   Neutral\n",
       "4557   covid vaccine jab administered quick easy and...  Positive\n",
       "4558   vaccine jab done today very efficiently done ...  Positive\n",
       "4559  is the  vaccine safe yes deaths reported in no...  Positive\n",
       "\n",
       "[4560 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vaderSentiment\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "#l=analyser.polarity_scores('Nazim Uddin is not a good advisor')\n",
    "#print(l)\n",
    "\n",
    "scores=[]\n",
    "for i in range(len(new_df['text'])):\n",
    "    score = analyser.polarity_scores(new_df['text'][i])\n",
    "    score=score['compound']\n",
    "    scores.append(score)\n",
    "sentiment=[]\n",
    "for i in scores:\n",
    "    if i>=0.05:\n",
    "        sentiment.append('Positive')\n",
    "    elif i<=(-0.05):\n",
    "        sentiment.append('Negative')\n",
    "    else:\n",
    "        sentiment.append('Neutral')\n",
    "        \n",
    "new_df['sentiment']=pd.Series(np.array(sentiment))\n",
    "\n",
    "#print(scores)\n",
    "print(max(scores))\n",
    "print(min(scores))\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dp3Pa1-EwDYR"
   },
   "source": [
    "# Coverting Sentiment In Numaric Value Using LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "84URQjKGwDYS",
    "outputId": "3768a4d5-96dd-4363-f003-2bbd548497df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>numaric_presentatin_of_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>while the world has been on the wrong side of ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus sputnikv astrazeneca pfizerbiontec...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facts are immutable senator even when youre no...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explain to me again why we need a vaccine bori...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>does anyone have any useful adviceguidance for...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it is a bit sad to claim the fame for success ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>there have not been many bright days in  but h...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>covid vaccine you getting it covidvaccine  pfi...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>covidvaccine states will start getting  monday...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0  same folks said daikon paste could treat a cyt...  Positive   \n",
       "1  while the world has been on the wrong side of ...  Negative   \n",
       "2  coronavirus sputnikv astrazeneca pfizerbiontec...  Positive   \n",
       "3  facts are immutable senator even when youre no...   Neutral   \n",
       "4  explain to me again why we need a vaccine bori...   Neutral   \n",
       "5  does anyone have any useful adviceguidance for...  Positive   \n",
       "6  it is a bit sad to claim the fame for success ...  Positive   \n",
       "7  there have not been many bright days in  but h...  Positive   \n",
       "8  covid vaccine you getting it covidvaccine  pfi...   Neutral   \n",
       "9  covidvaccine states will start getting  monday...   Neutral   \n",
       "\n",
       "   numaric_presentatin_of_sentiment  \n",
       "0                                 2  \n",
       "1                                 0  \n",
       "2                                 2  \n",
       "3                                 1  \n",
       "4                                 1  \n",
       "5                                 2  \n",
       "6                                 2  \n",
       "7                                 2  \n",
       "8                                 1  \n",
       "9                                 1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "new_df['numaric_presentatin_of_sentiment']=new_df[['sentiment']].apply(enc.fit_transform)\n",
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "hzT_8lr7wDYS",
    "outputId": "9723dec7-cf06-43cc-ccfa-6a03ad46311c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numaric_presentatin_of_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>1843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          numaric_presentatin_of_sentiment\n",
       "Neutral                               1843\n",
       "Positive                              1841\n",
       "Negative                               876"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment_count_table=pd.DataFrame(new_df['numaric_presentatin_of_sentiment'].value_counts())\n",
    "Sentiment_count_table.set_index(pd.Series(['Neutral','Positive','Negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OtoT1jowDYS"
   },
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fit the CountVectorizer to the training data\n",
    "vect = CountVectorizer().fit(new_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aacommunities', 'dilemma', 'jooly', 'proving', 'uns']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8676"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4560x8676 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 62723 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(new_df['text'])\n",
    "\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression on Countvactorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shafayet/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/shafayet/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/shafayet/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/shafayet/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/shafayet/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/shafayet/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/shafayet/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/shafayet/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/shafayet/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7662280701754385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shafayet/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.74780702, 0.77631579, 0.75657895, 0.76973684, 0.75219298,\n",
       "       0.76315789, 0.79385965, 0.79605263, 0.75438596, 0.75219298])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score  #KFold Model selection\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "pred=cross_val_score(LogisticRegression(),X_train_vectorized,new_df.numaric_presentatin_of_sentiment,cv=10) #cross_val_score() return accuracy list accroding to cv values\n",
    "print(pred.mean())\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM on Countvactorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7605263157894736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.75877193, 0.75877193, 0.75767544, 0.79385965, 0.73355263])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score  #KFold Model selection\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pred=cross_val_score(SVC(kernel='linear'),X_train_vectorized,new_df.numaric_presentatin_of_sentiment)#cross_val_score() return accuracy list accroding to cv values\n",
    "print(pred.mean())\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier on Countvactorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7359649122807017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.70833333, 0.74780702, 0.71710526, 0.73245614, 0.71052632,\n",
       "       0.75877193, 0.7872807 , 0.77192982, 0.71929825, 0.70614035])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pred=cross_val_score(RandomForestClassifier(n_estimators=200),X_train_vectorized,new_df.numaric_presentatin_of_sentiment,cv=10)#cross_val_score() return accuracy list accroding to cv values\n",
    "print(pred.mean())\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>ache</th>\n",
       "      <th>aches</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>yorkteachingnhs</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4557</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4560 rows √ó 1439 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abc  able  about  above  absolute  absolutely  access  according  ache  \\\n",
       "0     0.0   0.0    0.0    0.0       0.0         0.0     0.0        0.0   0.0   \n",
       "1     0.0   0.0    0.0    0.0       0.0         0.0     0.0        0.0   0.0   \n",
       "2     0.0   0.0    0.0    0.0       0.0         0.0     0.0        0.0   0.0   \n",
       "3     0.0   0.0    0.0    0.0       0.0         0.0     0.0        0.0   0.0   \n",
       "4     0.0   0.0    0.0    0.0       0.0         0.0     0.0        0.0   0.0   \n",
       "...   ...   ...    ...    ...       ...         ...     ...        ...   ...   \n",
       "4555  0.0   0.0    0.0    0.0       0.0         0.0     0.0        0.0   0.0   \n",
       "4556  0.0   0.0    0.0    0.0       0.0         0.0     0.0        0.0   0.0   \n",
       "4557  0.0   0.0    0.0    0.0       0.0         0.0     0.0        0.0   0.0   \n",
       "4558  0.0   0.0    0.0    0.0       0.0         0.0     0.0        0.0   0.0   \n",
       "4559  0.0   0.0    0.0    0.0       0.0         0.0     0.0        0.0   0.0   \n",
       "\n",
       "      aches  ...       yes  yesterday  yet  york  yorkteachingnhs       you  \\\n",
       "0       0.0  ...  0.000000        0.0  0.0   0.0              0.0  0.000000   \n",
       "1       0.0  ...  0.000000        0.0  0.0   0.0              0.0  0.000000   \n",
       "2       0.0  ...  0.000000        0.0  0.0   0.0              0.0  0.000000   \n",
       "3       0.0  ...  0.000000        0.0  0.0   0.0              0.0  0.214558   \n",
       "4       0.0  ...  0.000000        0.0  0.0   0.0              0.0  0.000000   \n",
       "...     ...  ...       ...        ...  ...   ...              ...       ...   \n",
       "4555    0.0  ...  0.000000        0.0  0.0   0.0              0.0  0.000000   \n",
       "4556    0.0  ...  0.000000        0.0  0.0   0.0              0.0  0.000000   \n",
       "4557    0.0  ...  0.000000        0.0  0.0   0.0              0.0  0.000000   \n",
       "4558    0.0  ...  0.000000        0.0  0.0   0.0              0.0  0.000000   \n",
       "4559    0.0  ...  0.343747        0.0  0.0   0.0              0.0  0.000000   \n",
       "\n",
       "      your     youre  yours  youtube  \n",
       "0      0.0  0.000000    0.0      0.0  \n",
       "1      0.0  0.000000    0.0      0.0  \n",
       "2      0.0  0.000000    0.0      0.0  \n",
       "3      0.0  0.422454    0.0      0.0  \n",
       "4      0.0  0.000000    0.0      0.0  \n",
       "...    ...       ...    ...      ...  \n",
       "4555   0.0  0.000000    0.0      0.0  \n",
       "4556   0.0  0.000000    0.0      0.0  \n",
       "4557   0.0  0.000000    0.0      0.0  \n",
       "4558   0.0  0.000000    0.0      0.0  \n",
       "4559   0.0  0.000000    0.0      0.0  \n",
       "\n",
       "[4560 rows x 1439 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfvect=TfidfVectorizer(min_df=5) #min_df=5 means it takes world only that has more than equal frequency 5.\n",
    "trans=tfvect.fit_transform(new_df['text'])\n",
    "len(tfvect.get_feature_names())\n",
    "tfidf=pd.DataFrame(trans.toarray(),columns=tfvect.get_feature_names())\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression on TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7166666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "pred=cross_val_score(LogisticRegression(),tfidf,new_df.numaric_presentatin_of_sentiment,cv=10)\n",
    "print(pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM on TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4041666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.40350877, 0.40350877, 0.40460526, 0.40460526, 0.40460526])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pred=cross_val_score(SVC(kernel='linear',C=1),tfidf,new_df.numaric_presentatin_of_sentiment,cv=10)\n",
    "print(pred.mean())\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pred=cross_val_score(RandomForestClassifier(n_estimators=200),tfidf,new_df.numaric_presentatin_of_sentiment,cv=10)\n",
    "print(pred.mean())\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Applied n-grams but it's giving even more worst accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "D2OIqGsnwDYN",
    "cvGuwqsTwDYO",
    "QVre_IpZwDYP",
    "n0AAyQIvwDYP",
    "O2kp08nYwDYQ",
    "dp3Pa1-EwDYR",
    "Q6naT_HMwDYT",
    "e05kU5K7wDYU",
    "zYXp87rYwDYU",
    "RJX8V7z9wDYV",
    "Z5eCH2DdwDYW",
    "gY7rg35PwDYX",
    "u-KnPdqYwDYX",
    "TbVODNDkwDYZ"
   ],
   "name": "Copy of Copy of Pfizer Vaccine Tweet Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
